<!doctype html><html><head><title>Edition 22 A Framework to Securely Use LLMs in Companies - Part 2 Managing Risk</title><base href="../../"><meta id="root-path" root-path="../../"><link rel="icon" sizes="96x96" href="https://publish-01.obsidian.md/access/f786db9fac45774fa4f0d8112e232d67/favicon-96x96.png"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=yes,minimum-scale=1,maximum-scale=5"><meta charset="UTF-8"><link rel="stylesheet" href="lib/styles/obsidian-styles.css"><link rel="stylesheet" href="lib/styles/theme.css"><link rel="stylesheet" href="lib/styles/plugin-styles.css"><link rel="stylesheet" href="lib/styles/snippets.css"><link rel="stylesheet" href="lib/styles/generated-styles.css"><style>body.css-settings-manager{--heading-spacing:0}</style><script type="module" src="lib/scripts/graph_view.js"></script><script src="lib/scripts/graph_wasm.js"></script><script src="lib/scripts/tinycolor.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/pixi.js/7.2.4/pixi.min.js" integrity="sha512-Ch/O6kL8BqUwAfCF7Ie5SX1Hin+BJgYH4pNjRqXdTEqMsis1TUYg+j6nnI9uduPjGaj7DN4UKCZgpvoExt6dkw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><script src="lib/scripts/webpage.js"></script><script src="lib/scripts/generated.js"></script></head><body class="theme-dark mod-macos native-scrollbars show-inline-title minimal-dracula-dark colorful-active system-shade minimal-dark-black callouts-default trim-cols checkbox-circle pdf-seamless-on pdf-invert-dark pdf-blend-light metadata-heading-off sidebar-tabs-default ribbon-hidden maximize-tables-off tabs-default tab-stack-top minimal-tab-title-hover is-fullscreen loading"><div class="webpage-container"><div class="sidebar-left sidebar"><div class="sidebar-container"><div class="sidebar-sizer"><div class="sidebar-content-positioner"><div class="sidebar-content"><div><label class="theme-toggle-container" for="theme_toggle"><input class="theme-toggle-input" type="checkbox" id="theme_toggle"><div class="toggle-background"></div></label></div><div class="tree-container file-tree mod-nav-indicator" data-depth="0"><div class="tree-header"><span class="sidebar-section-header">obsidian-notes</span><button class="clickable-icon collapse-tree-button is-collapsed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></svg></button></div><div class="tree-scroll-area"><div class="tree-item mod-tree-folder mod-collapsible is-collapsed" data-depth="1"><div class="tree-item-contents"><a class="internal-link tree-item-link"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">2_Literature Notes</span></a></div><div class="tree-item-children" style="display:none"><div class="tree-item mod-tree-folder mod-collapsible is-collapsed" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">Articles</span></a></div><div class="tree-item-children" style="display:none"><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/3-things-chatgpt-needs-before-it-can-be-deployed-in-customer-service.html"><span class="tree-item-title">3 Things ChatGPT Needs Before it Can be Deployed in Customer Service</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/a-developer’s-guide-to-llmops-operationalizing-llms-at-scale.html"><span class="tree-item-title">A Developer’s Guide To LLMOps Operationalizing LLMs At Scale</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/age-of-industrialized-ai-dan-jeffries-llms-in-production-conference.html"><span class="tree-item-title">Age of Industrialized AI Dan Jeffries LLMs in Production Conference</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/ai-agents-when-and-how-to-implement.html"><span class="tree-item-title">AI Agents When and How to Implement</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/best-practices-for-deploying-language-models.html"><span class="tree-item-title">Best Practices for Deploying Language Models</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/best-practices-for-deploying-large-language-models-(llms)-in-production.html"><span class="tree-item-title">Best Practices for Deploying Large Language Models (LLMs) in Production</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/best-practices-for-large-language-model-(llm)-deployment.html"><span class="tree-item-title">Best Practices for Large Language Model (LLM) Deployment</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/best-practices-for-monitoring-large-language-models.html"><span class="tree-item-title">Best Practices for Monitoring Large Language Models</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/building-llm-applications-for-production-chip-huyen-llms-in-prod-conference.html"><span class="tree-item-title">Building LLM Applications for Production Chip Huyen LLMs in Prod Conference</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/comply-or-die-the-rise-of-the-ai-governance-stack.html"><span class="tree-item-title">Comply or Die The Rise of the AI Governance Stack</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/concepts-for-reliability-of-llms-in-production.html"><span class="tree-item-title">Concepts for Reliability of LLMs in Production</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/controlled-and-compliant-ai-applications-daniel-whitenack-llms-in-production-conference-part-2.html"><span class="tree-item-title">Controlled and Compliant AI Applications Daniel Whitenack LLMs in Production Conference Part 2</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/deploying-large-language-models-in-production-llm-deployment-challenges.html"><span class="tree-item-title">Deploying Large Language Models in Production LLM Deployment Challenges</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/deploying-large-language-models-in-production-orchestrating-llms.html"><span class="tree-item-title">Deploying Large Language Models in Production Orchestrating LLMs</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/deploying-large-language-models-in-production-the-anatomy-of-llm-applications.html"><span class="tree-item-title">Deploying Large Language Models in Production The Anatomy of LLM Applications</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/design-patterns-for-llm-systems-&amp;-products.html"><span class="tree-item-title">Design Patterns for LLM Systems &amp; Products</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/devtools-for-language-models-—-predicting-the-future.html"><span class="tree-item-title">DevTools for Language Models — Predicting the Future</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/edition-21-a-framework-to-securely-use-llms-in-companies-part-1-overview-of-risks.html"><span class="tree-item-title">Edition 21 A Framework to Securely Use LLMs in Companies - Part 1 Overview of Risks</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/edition-22-a-framework-to-securely-use-llms-in-companies-part-2-managing-risk.html"><span class="tree-item-title">Edition 22 A Framework to Securely Use LLMs in Companies - Part 2 Managing Risk</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/emerging-architectures-for-llm-applications.html"><span class="tree-item-title">Emerging Architectures for LLM Applications</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/emerging-architectures-for-llms-applications-datasciencedojo.html"><span class="tree-item-title">Emerging Architectures for LLMs Applications - datasciencedojo</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/emerging-patterns-for-llms-in-production-willem-pienaar-llms-in-prod-conference-lightning-talk.html"><span class="tree-item-title">Emerging Patterns for LLMs in Production Willem Pienaar LLMs in Prod Conference Lightning Talk</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/ensuring-accuracy-and-quality-in-llm-driven-products-adam-nolte-llms-in-prod-conference.html"><span class="tree-item-title">Ensuring Accuracy and Quality in LLM-driven Products Adam Nolte LLMs in Prod Conference</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/evaluating-rag-pipelines-with-ragas-+-langsmith.html"><span class="tree-item-title">Evaluating RAG Pipelines With Ragas + LangSmith</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/exploring-llm-apps-the-langchain-paradigm-and-future-alternatives.html"><span class="tree-item-title">Exploring LLM Apps The LangChain Paradigm and Future Alternatives</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/finetuning-large-language-models.html"><span class="tree-item-title">Finetuning Large Language Models</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/fmopsllmops-operationalize-generative-ai-and-differences-with-mlops.html"><span class="tree-item-title">FMOpsLLMOps Operationalize Generative AI and Differences With MLOps</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/four-ways-that-enterprises-deploy-llms.html"><span class="tree-item-title">Four Ways That Enterprises Deploy LLMs</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/from-concept-to-practice-learnings-from-llms-for-enterprise-production-–-part-0.html"><span class="tree-item-title">From Concept to Practice Learnings From LLMs for Enterprise Production – Part 0</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/from-out-of-the-box-to-tailor-made-developing-and-deploying-enterprise-generative-ai-tools.html"><span class="tree-item-title">From Out-of-the-Box to Tailor-Made Developing and Deploying Enterprise Generative AI Tools</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/generative-ai-a-creative-new-world.html"><span class="tree-item-title">Generative AI A Creative New World</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/generative-ai-is-exploding-these-are-the-most-important-trends-to-know.html"><span class="tree-item-title">Generative AI Is Exploding. These Are the Most Important Trends to Know</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/generative-ai’s-act-two.html"><span class="tree-item-title">Generative AI’s Act Two</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/guardrails-for-llms-a-practical-approach-shreya-rajpal-llms-in-prod-conference-part-2.html"><span class="tree-item-title">Guardrails for LLMs A Practical Approach Shreya Rajpal LLMs in Prod Conference Part 2</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/guardrails-what-are-they-and-how-can-you-use-nemo-and-guardrails-ai-to-safeguard-llms.html"><span class="tree-item-title">Guardrails What Are They and How Can You Use NeMo and Guardrails AI to Safeguard LLMs</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/guiding-llms-while-staying-in-the-driver's-seat-jacob-van-gogh-llms-in-prod-con-lightning-talk.html"><span class="tree-item-title">Guiding LLMs While Staying in the Driver's Seat Jacob Van Gogh LLMs in Prod Con Lightning Talk</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/harry-browne’s-17-golden-rules-of-financial-safety.html"><span class="tree-item-title">Harry Browne’s 17 Golden Rules of Financial Safety</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/how-ray-solves-common-production-challenges-for-generative-ai-infrastructure.html"><span class="tree-item-title">How Ray Solves Common Production Challenges for Generative AI Infrastructure</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/how-to-evaluate-your-llm-applications.html"><span class="tree-item-title">How to Evaluate Your LLM Applications</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/illustrating-reinforcement-learning-from-human-feedback.html"><span class="tree-item-title">Illustrating Reinforcement Learning From Human Feedback</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/improving-llms-in-production-with-observability.html"><span class="tree-item-title">Improving LLMs in Production With Observability</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/introduction-to-retrieval-augmented-generation.html"><span class="tree-item-title">Introduction to Retrieval Augmented Generation</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/llm-deployment-with-nlp-models-meryem-arik-llms-in-production-conference-lightning-talk-2.html"><span class="tree-item-title">LLM Deployment With NLP Models Meryem Arik LLMs in Production Conference Lightning Talk 2</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/llm-evaluation-assessing-large-language-models-using-their-peers.html"><span class="tree-item-title">LLM Evaluation Assessing Large Language Models Using Their Peers</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/llm-observability-one-small-step-for-spans,-one-giant-leap-for-span-kinds.html"><span class="tree-item-title">LLM Observability One Small Step for Spans, One Giant Leap for Span-Kinds</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/llmops-the-future-of-mlops-for-generative-ai.html"><span class="tree-item-title">LLMOps The Future of MLOps for Generative AI</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/ml's-hidden-tasks-a-checklist-for-developers-when-building-ml-systems.html"><span class="tree-item-title">ML's Hidden Tasks A Checklist for Developers When Building ML Systems</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/monitoring-llms-metrics,-challenges,-&amp;-hallucinations.html"><span class="tree-item-title">Monitoring LLMs Metrics, Challenges, &amp; Hallucinations</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/no-rose-without-a-thorn-obstacles-to-successful-llm-deployments-tanmay-chopra-llms-in-prod.html"><span class="tree-item-title">No Rose Without a Thorn - Obstacles to Successful LLM Deployments Tanmay Chopra LLMs in Prod</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/nvidia-enables-trustworthy,-safe,-and-secure-large-language-model-conversational-systems.html"><span class="tree-item-title">NVIDIA Enables Trustworthy, Safe, and Secure Large Language Model Conversational Systems</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/production-deployment-checklist-for-machine-learning-models.html"><span class="tree-item-title">Production Deployment Checklist for Machine Learning Models</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/security-challenges-in-llm-adoption-for-enterprises-and-how-to-solve-them.html"><span class="tree-item-title">Security Challenges in LLM Adoption for Enterprises and How to Solve Them</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/the-confidence-checklist-for-llms-in-production-rohit-agarwal-llms-in-prod-conference-part-2.html"><span class="tree-item-title">The Confidence Checklist for LLMs in Production Rohit Agarwal LLMs in Prod Conference Part 2</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/the-generative-ai-life-cycle.html"><span class="tree-item-title">The Generative AI Life-Cycle</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/the-gradient-of-generative-ai-release-methods-and-considerations.html"><span class="tree-item-title">The Gradient of Generative AI Release Methods and Considerations</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/the-new-language-model-stack.html"><span class="tree-item-title">The New Language Model Stack</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/the_practical_guide_deploying_large_language_models.html"><span class="tree-item-title">The_Practical_Guide_Deploying_Large_Language_Models</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/understanding-llmops-large-language-model-operations.html"><span class="tree-item-title">Understanding LLMOps Large Language Model Operations</span></a></div><div class="tree-item-children"></div></div></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/glr-–-references.html"><span class="tree-item-title">GLR – References</span></a></div><div class="tree-item-children"></div></div></div></div><div class="tree-item mod-tree-file" data-depth="1"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="mind-map-–-generative-ai-release-checklist-3.html"><span class="tree-item-title">Mind Map – Generative AI Release Checklist 3</span></a></div><div class="tree-item-children"></div></div></div></div></div></div></div></div><div class="sidebar-gutter"><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div></div><div class="document-container show"><div class="markdown-preview-view markdown-rendered node-insert-event is-readable-line-width allow-fold-headings show-indentation-guide allow-fold-lists show-properties" style="tab-size:4"><style id="MJX-CHTML-styles">mjx-container[jax=CHTML]{line-height:0}mjx-container [space="1"]{margin-left:.111em}mjx-container [space="2"]{margin-left:.167em}mjx-container [space="3"]{margin-left:.222em}mjx-container [space="4"]{margin-left:.278em}mjx-container [space="5"]{margin-left:.333em}mjx-container [rspace="1"]{margin-right:.111em}mjx-container [rspace="2"]{margin-right:.167em}mjx-container [rspace="3"]{margin-right:.222em}mjx-container [rspace="4"]{margin-right:.278em}mjx-container [rspace="5"]{margin-right:.333em}mjx-container [size="s"]{font-size:70.7%}mjx-container [size=ss]{font-size:50%}mjx-container [size=Tn]{font-size:60%}mjx-container [size=sm]{font-size:85%}mjx-container [size=lg]{font-size:120%}mjx-container [size=Lg]{font-size:144%}mjx-container [size=LG]{font-size:173%}mjx-container [size=hg]{font-size:207%}mjx-container [size=HG]{font-size:249%}mjx-container [width=full]{width:100%}mjx-box{display:inline-block}mjx-block{display:block}mjx-itable{display:inline-table}mjx-row{display:table-row}mjx-row>*{display:table-cell}mjx-mtext{display:inline-block}mjx-mstyle{display:inline-block}mjx-merror{display:inline-block;color:red;background-color:#ff0}mjx-mphantom{visibility:hidden}mjx-assistive-mml{top:0;left:0;clip:rect(1px,1px,1px,1px);user-select:none;position:absolute!important;padding:1px 0 0!important;border:0!important;display:block!important;width:auto!important;overflow:hidden!important}mjx-assistive-mml[display=block]{width:100%!important}mjx-math{display:inline-block;text-align:left;line-height:0;text-indent:0;font-style:normal;font-weight:400;font-size:100%;letter-spacing:normal;border-collapse:collapse;overflow-wrap:normal;word-spacing:normal;white-space:nowrap;direction:ltr;padding:1px 0}mjx-container[jax=CHTML][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=CHTML][display=true][width=full]{display:flex}mjx-container[jax=CHTML][display=true] mjx-math{padding:0}mjx-container[jax=CHTML][justify=left]{text-align:left}mjx-container[jax=CHTML][justify=right]{text-align:right}mjx-mo{display:inline-block;text-align:left}mjx-stretchy-h{display:inline-table;width:100%}mjx-stretchy-h>*{display:table-cell;width:0}mjx-stretchy-h>*>mjx-c{display:inline-block;transform:scaleX(1)}mjx-stretchy-h>*>mjx-c::before{display:inline-block;width:initial}mjx-stretchy-h>mjx-ext{overflow:clip visible;width:100%}mjx-stretchy-h>mjx-ext>mjx-c::before{transform:scaleX(500)}mjx-stretchy-h>mjx-ext>mjx-c{width:0}mjx-stretchy-h>mjx-beg>mjx-c{margin-right:-.1em}mjx-stretchy-h>mjx-end>mjx-c{margin-left:-.1em}mjx-stretchy-v{display:inline-block}mjx-stretchy-v>*{display:block}mjx-stretchy-v>mjx-beg{height:0}mjx-stretchy-v>mjx-end>mjx-c{display:block}mjx-stretchy-v>*>mjx-c{transform:scaleY(1);transform-origin:left center;overflow:hidden}mjx-stretchy-v>mjx-ext{display:block;height:100%;box-sizing:border-box;border:0 solid transparent;overflow:visible clip}mjx-stretchy-v>mjx-ext>mjx-c::before{width:initial;box-sizing:border-box}mjx-stretchy-v>mjx-ext>mjx-c{transform:scaleY(500) translateY(.075em);overflow:visible}mjx-mark{display:inline-block;height:0}mjx-c{display:inline-block}mjx-utext{display:inline-block;padding:.75em 0 .2em}mjx-mi{display:inline-block;text-align:left}mjx-msup{display:inline-block;text-align:left}mjx-mn{display:inline-block;text-align:left}mjx-c::before{display:block;width:0}.MJX-TEX{font-family:MJXZERO,MJXTEX}.TEX-B{font-family:MJXZERO,MJXTEX-B}.TEX-I{font-family:MJXZERO,MJXTEX-I}.TEX-MI{font-family:MJXZERO,MJXTEX-MI}.TEX-BI{font-family:MJXZERO,MJXTEX-BI}.TEX-S1{font-family:MJXZERO,MJXTEX-S1}.TEX-S2{font-family:MJXZERO,MJXTEX-S2}.TEX-S3{font-family:MJXZERO,MJXTEX-S3}.TEX-S4{font-family:MJXZERO,MJXTEX-S4}.TEX-A{font-family:MJXZERO,MJXTEX-A}.TEX-C{font-family:MJXZERO,MJXTEX-C}.TEX-CB{font-family:MJXZERO,MJXTEX-CB}.TEX-FR{font-family:MJXZERO,MJXTEX-FR}.TEX-FRB{font-family:MJXZERO,MJXTEX-FRB}.TEX-SS{font-family:MJXZERO,MJXTEX-SS}.TEX-SSB{font-family:MJXZERO,MJXTEX-SSB}.TEX-SSI{font-family:MJXZERO,MJXTEX-SSI}.TEX-SC{font-family:MJXZERO,MJXTEX-SC}.TEX-T{font-family:MJXZERO,MJXTEX-T}.TEX-V{font-family:MJXZERO,MJXTEX-V}.TEX-VB{font-family:MJXZERO,MJXTEX-VB}mjx-stretchy-h mjx-c,mjx-stretchy-v mjx-c{font-family:MJXZERO,MJXTEX-S1,MJXTEX-S4,MJXTEX,MJXTEX-A!important}@font-face{font-family:MJXZERO;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Zero.woff") format("woff")}@font-face{font-family:MJXTEX;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Main-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-B;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Main-Bold.woff") format("woff")}@font-face{font-family:MJXTEX-I;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Math-Italic.woff") format("woff")}@font-face{font-family:MJXTEX-MI;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Main-Italic.woff") format("woff")}@font-face{font-family:MJXTEX-BI;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Math-BoldItalic.woff") format("woff")}@font-face{font-family:MJXTEX-S1;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Size1-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-S2;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Size2-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-S3;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Size3-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-S4;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Size4-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-A;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_AMS-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-C;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-CB;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Bold.woff") format("woff")}@font-face{font-family:MJXTEX-FR;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Fraktur-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-FRB;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Fraktur-Bold.woff") format("woff")}@font-face{font-family:MJXTEX-SS;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_SansSerif-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-SSB;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_SansSerif-Bold.woff") format("woff")}@font-face{font-family:MJXTEX-SSI;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_SansSerif-Italic.woff") format("woff")}@font-face{font-family:MJXTEX-SC;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Script-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-T;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Typewriter-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-V;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Vector-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-VB;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Vector-Bold.woff") format("woff")}mjx-c.mjx-c28::before{padding:.75em .389em .25em 0;content:"("}mjx-c.mjx-c1D43C.TEX-I::before{padding:.683em .504em 0 0;content:"I"}mjx-c.mjx-c1D434.TEX-I::before{padding:.716em .75em 0 0;content:"A"}mjx-c.mjx-c29::before{padding:.75em .389em .25em 0;content:")"}mjx-c.mjx-c33::before{padding:.665em .5em .022em 0;content:"3"}</style><div class="markdown-preview-sizer markdown-preview-section" style="min-height:1306px"><div class="markdown-preview-pusher" style="width:1px;height:.1px;margin-bottom:0"></div><div class="mod-header"></div><div><pre class="frontmatter language-yaml" tabindex="0" style="display:none"><code class="language-yaml is-loaded"><span class="token key atrule">tags</span><span class="token punctuation">:</span> project/grey<span class="token punctuation">-</span>llm type/blog type/literature type/note 
<span class="token key atrule">created</span><span class="token punctuation">:</span> <span class="token datetime number">2023-10-28</span>
<span class="token key atrule">link</span><span class="token punctuation">:</span> https<span class="token punctuation">:</span>//boringappsec.substack.com/p/edition<span class="token punctuation">-</span>22<span class="token punctuation">-</span>a<span class="token punctuation">-</span>framework<span class="token punctuation">-</span>to<span class="token punctuation">-</span>securely</code><button class="copy-code-button">Copy</button></pre></div><div class="heading-wrapper"><h1 data-heading="Edition 22: A Framework to Securely Use LLMs in Companies - Part 2: Managing Risk" class="heading" id="Edition_22:_A_Framework_to_Securely_Use_LLMs_in_Companies_-_Part_2:_Managing_Risk"><div class="heading-before"></div>Edition 22: A Framework to Securely Use LLMs in Companies - Part 2: Managing Risk<div class="heading-after">...</div></h1><div class="heading-children"><div><p><img alt="rw-book-cover" src="https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b3cf0d3-82af-44fb-8a10-df7fd609f784_1024x1024.png" referrerpolicy="no-referrer"></p></div><div class="heading-wrapper"><h2 data-heading="Highlights" class="heading" id="Highlights"><div class="heading-before"></div><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle" style="width:24px;max-width:100%"><path d="M3 8L12 17L21 8"></path></svg></div>Highlights<div class="heading-after">...</div></h2><div class="heading-children"><div><ul><li data-line="0">While open source models can be used for free (or cost very little), the total cost of ownership (TCO) including diverting engineering resources, and uncertain infrastructure costs can be quite high. There is also the opportunity cost of having to de-prioritize other initiatives. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdvpwq39z1fsq8bdc33hw4xe" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdvpwq39z1fsq8bdc33hw4xe" target="_blank">View Highlight</a>)</li><li data-line="1">This allows you to write rules to mask sensitive data, keep a tab on costs and monitor for abuse. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdvq2vrv73bn0cyx499yp8k4" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdvq2vrv73bn0cyx499yp8k4" target="_blank">View Highlight</a>)</li><li data-line="2">An LLM gateway to route traffic (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hcwsw8qpvd4017dda60v9mbh" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hcwsw8qpvd4017dda60v9mbh" target="_blank">View Highlight</a>)</li><li data-line="3"><a data-tooltip-position="top" aria-label="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25cf55ff-0297-4586-b37e-5ef376342cbb_972x645.png" rel="noopener" class="external-link" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25cf55ff-0297-4586-b37e-5ef376342cbb_972x645.png" target="_blank"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25cf55ff-0297-4586-b37e-5ef376342cbb_972x645.png" referrerpolicy="no-referrer"></a><br>In addition to managing risks, in a Public SaaS model, the LLM gateway can also provide a routing mechanism to make things simpler for applications. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hcwswcf2aw3vv2w8stdhybfh" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hcwswcf2aw3vv2w8stdhybfh" target="_blank">View Highlight</a>)</li><li data-line="5"><a data-tooltip-position="top" aria-label="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faac1b549-b03f-406f-bb4c-a1a7a8789659_1065x632.png" rel="noopener" class="external-link" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faac1b549-b03f-406f-bb4c-a1a7a8789659_1065x632.png" target="_blank"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faac1b549-b03f-406f-bb4c-a1a7a8789659_1065x632.png" referrerpolicy="no-referrer"></a><br>The same gateway can be tuned to manage a slightly different set of risks in the Private SaaS model (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hcwswgk7rgt8ddpr18pc1d7v" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hcwswgk7rgt8ddpr18pc1d7v" target="_blank">View Highlight</a>)</li><li data-line="7"><strong>Regular auditing/testing of implemented solutions:</strong> Even with the LLM gateway in place, there is a need for good old pen testing / red teaming activities. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hcwswxvjj25hhjmx06s7492n" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hcwswxvjj25hhjmx06s7492n" target="_blank">View Highlight</a>)</li><li data-line="8"><strong>A monitoring layer to monitor LLM usage:</strong> While the gateway layer helps application teams to build the integration securely, it's reasonable to assume that most medium-large organizations will have “shadow” usage. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hcwsxdvsc5prgxrfx6mk0f9s" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hcwsxdvsc5prgxrfx6mk0f9s" target="_blank">View Highlight</a>)</li><li data-line="9"><strong>DNS monitoring</strong> can be leveraged to detect if applications are making calls to unapproved LLM services. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hcwsydr18n95dtdbsys90m9f" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hcwsydr18n95dtdbsys90m9f" target="_blank">View Highlight</a>)</li><li data-line="10"><strong>Cost monitoring</strong>: A tool to monitor how much money is being sent on requests made to LLM tools. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hcwsymq8j3acz3jwvgecj4kh" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hcwsymq8j3acz3jwvgecj4kh" target="_blank">View Highlight</a>)</li><li data-line="11"><strong>Sensitive data monitoring (PII, PHI):</strong> Analyze logs from the LLM gateway and the applications to see if there are hints of sensitive data being accidentally sent to 3rd party LLMs. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hcwsytk0kxahbacnmys6zwax" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hcwsytk0kxahbacnmys6zwax" target="_blank">View Highlight</a>)</li><li data-line="12"><strong>Static monitoring:</strong><ol><li data-line="13">Write <strong>static analysis</strong> (Semgrep, CodeQL) rules to detect if any applications are integrating with LLM libraries. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hcwsyzr1dttmjttqbp3nnf3h" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hcwsyzr1dttmjttqbp3nnf3h" target="_blank">View Highlight</a>)</li></ol></li><li data-line="14">Leverage SCA tools to check if <strong>insecure LLM libraries</strong> are used in applications integrating with LLMs (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hcwszch9wc9xxdxtme8vghva" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hcwszch9wc9xxdxtme8vghva" target="_blank">View Highlight</a>)</li><li data-line="15"><strong>Container image scanning:</strong> Generate an SBOM and detect if insecure, 3rd party LLM library is used (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hcwsz837mr2r7hat9ajwr3rm" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hcwsz837mr2r7hat9ajwr3rm" target="_blank">View Highlight</a>)</li></ul></div><div class="mod-footer"></div></div></div></div></div></div></div></div><div class="sidebar-right sidebar"><div class="sidebar-gutter"><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-container"><div class="sidebar-sizer"><div class="sidebar-content-positioner"><div class="sidebar-content"><div class="graph-view-wrapper"><div class="sidebar-section-header">Interactive Graph</div><div class="graph-view-placeholder"><div class="graph-view-container"><div class="graph-icon graph-expand" role="button" aria-label="Expand" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><line x1="7" y1="17" x2="17" y2="7"></line><polyline points="7 7 17 7 17 17"></polyline></svg></div><canvas id="graph-canvas" width="512px" height="512px"></canvas></div></div></div><div class="tree-container outline-tree" data-depth="0"><div class="tree-header"><span class="sidebar-section-header">Table Of Contents</span><button class="clickable-icon collapse-tree-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></svg></button></div><div class="tree-scroll-area"><div class="tree-item" data-depth="1"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="#Edition_22:_A_Framework_to_Securely_Use_LLMs_in_Companies_-_Part_2:_Managing_Risk"><span class="tree-item-title"><p>Edition 22: A Framework to Securely Use LLMs in Companies - Part 2: Managing Risk</p></span></a></div><div class="tree-item-children"><div class="tree-item" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="#Highlights"><span class="tree-item-title"><p>Highlights</p></span></a></div><div class="tree-item-children"></div></div></div></div></div></div></div></div></div></div></div></div></body></html>