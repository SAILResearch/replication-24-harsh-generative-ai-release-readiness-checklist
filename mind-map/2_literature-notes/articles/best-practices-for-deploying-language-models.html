<!doctype html><html><head><title>Best Practices for Deploying Language Models</title><base href="../../"><meta id="root-path" root-path="../../"><link rel="icon" sizes="96x96" href="https://publish-01.obsidian.md/access/f786db9fac45774fa4f0d8112e232d67/favicon-96x96.png"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=yes,minimum-scale=1,maximum-scale=5"><meta charset="UTF-8"><link rel="stylesheet" href="lib/styles/obsidian-styles.css"><link rel="stylesheet" href="lib/styles/theme.css"><link rel="stylesheet" href="lib/styles/plugin-styles.css"><link rel="stylesheet" href="lib/styles/snippets.css"><link rel="stylesheet" href="lib/styles/generated-styles.css"><style>body.css-settings-manager{--heading-spacing:0}</style><script type="module" src="lib/scripts/graph_view.js"></script><script src="lib/scripts/graph_wasm.js"></script><script src="lib/scripts/tinycolor.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/pixi.js/7.2.4/pixi.min.js" integrity="sha512-Ch/O6kL8BqUwAfCF7Ie5SX1Hin+BJgYH4pNjRqXdTEqMsis1TUYg+j6nnI9uduPjGaj7DN4UKCZgpvoExt6dkw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><script src="lib/scripts/webpage.js"></script><script src="lib/scripts/generated.js"></script></head><body class="theme-dark mod-macos native-scrollbars show-inline-title minimal-dracula-dark colorful-active system-shade minimal-dark-black callouts-default trim-cols checkbox-circle pdf-seamless-on pdf-invert-dark pdf-blend-light metadata-heading-off sidebar-tabs-default ribbon-hidden maximize-tables-off tabs-default tab-stack-top minimal-tab-title-hover is-fullscreen loading"><div class="webpage-container"><div class="sidebar-left sidebar"><div class="sidebar-container"><div class="sidebar-sizer"><div class="sidebar-content-positioner"><div class="sidebar-content"><div><label class="theme-toggle-container" for="theme_toggle"><input class="theme-toggle-input" type="checkbox" id="theme_toggle"><div class="toggle-background"></div></label></div><div class="tree-container file-tree mod-nav-indicator" data-depth="0"><div class="tree-header"><span class="sidebar-section-header">obsidian-notes</span><button class="clickable-icon collapse-tree-button is-collapsed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></svg></button></div><div class="tree-scroll-area"><div class="tree-item mod-tree-folder mod-collapsible is-collapsed" data-depth="1"><div class="tree-item-contents"><a class="internal-link tree-item-link"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">2_Literature Notes</span></a></div><div class="tree-item-children" style="display:none"><div class="tree-item mod-tree-folder mod-collapsible is-collapsed" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">Articles</span></a></div><div class="tree-item-children" style="display:none"><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/3-things-chatgpt-needs-before-it-can-be-deployed-in-customer-service.html"><span class="tree-item-title">3 Things ChatGPT Needs Before it Can be Deployed in Customer Service</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/a-developer’s-guide-to-llmops-operationalizing-llms-at-scale.html"><span class="tree-item-title">A Developer’s Guide To LLMOps Operationalizing LLMs At Scale</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/age-of-industrialized-ai-dan-jeffries-llms-in-production-conference.html"><span class="tree-item-title">Age of Industrialized AI Dan Jeffries LLMs in Production Conference</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/ai-agents-when-and-how-to-implement.html"><span class="tree-item-title">AI Agents When and How to Implement</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/best-practices-for-deploying-language-models.html"><span class="tree-item-title">Best Practices for Deploying Language Models</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/best-practices-for-deploying-large-language-models-(llms)-in-production.html"><span class="tree-item-title">Best Practices for Deploying Large Language Models (LLMs) in Production</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/best-practices-for-large-language-model-(llm)-deployment.html"><span class="tree-item-title">Best Practices for Large Language Model (LLM) Deployment</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/best-practices-for-monitoring-large-language-models.html"><span class="tree-item-title">Best Practices for Monitoring Large Language Models</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/building-llm-applications-for-production-chip-huyen-llms-in-prod-conference.html"><span class="tree-item-title">Building LLM Applications for Production Chip Huyen LLMs in Prod Conference</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/comply-or-die-the-rise-of-the-ai-governance-stack.html"><span class="tree-item-title">Comply or Die The Rise of the AI Governance Stack</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/concepts-for-reliability-of-llms-in-production.html"><span class="tree-item-title">Concepts for Reliability of LLMs in Production</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/controlled-and-compliant-ai-applications-daniel-whitenack-llms-in-production-conference-part-2.html"><span class="tree-item-title">Controlled and Compliant AI Applications Daniel Whitenack LLMs in Production Conference Part 2</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/deploying-large-language-models-in-production-llm-deployment-challenges.html"><span class="tree-item-title">Deploying Large Language Models in Production LLM Deployment Challenges</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/deploying-large-language-models-in-production-orchestrating-llms.html"><span class="tree-item-title">Deploying Large Language Models in Production Orchestrating LLMs</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/deploying-large-language-models-in-production-the-anatomy-of-llm-applications.html"><span class="tree-item-title">Deploying Large Language Models in Production The Anatomy of LLM Applications</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/design-patterns-for-llm-systems-&amp;-products.html"><span class="tree-item-title">Design Patterns for LLM Systems &amp; Products</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/devtools-for-language-models-—-predicting-the-future.html"><span class="tree-item-title">DevTools for Language Models — Predicting the Future</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/edition-21-a-framework-to-securely-use-llms-in-companies-part-1-overview-of-risks.html"><span class="tree-item-title">Edition 21 A Framework to Securely Use LLMs in Companies - Part 1 Overview of Risks</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/edition-22-a-framework-to-securely-use-llms-in-companies-part-2-managing-risk.html"><span class="tree-item-title">Edition 22 A Framework to Securely Use LLMs in Companies - Part 2 Managing Risk</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/emerging-architectures-for-llm-applications.html"><span class="tree-item-title">Emerging Architectures for LLM Applications</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/emerging-architectures-for-llms-applications-datasciencedojo.html"><span class="tree-item-title">Emerging Architectures for LLMs Applications - datasciencedojo</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/emerging-patterns-for-llms-in-production-willem-pienaar-llms-in-prod-conference-lightning-talk.html"><span class="tree-item-title">Emerging Patterns for LLMs in Production Willem Pienaar LLMs in Prod Conference Lightning Talk</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/ensuring-accuracy-and-quality-in-llm-driven-products-adam-nolte-llms-in-prod-conference.html"><span class="tree-item-title">Ensuring Accuracy and Quality in LLM-driven Products Adam Nolte LLMs in Prod Conference</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/evaluating-rag-pipelines-with-ragas-+-langsmith.html"><span class="tree-item-title">Evaluating RAG Pipelines With Ragas + LangSmith</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/exploring-llm-apps-the-langchain-paradigm-and-future-alternatives.html"><span class="tree-item-title">Exploring LLM Apps The LangChain Paradigm and Future Alternatives</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/finetuning-large-language-models.html"><span class="tree-item-title">Finetuning Large Language Models</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/fmopsllmops-operationalize-generative-ai-and-differences-with-mlops.html"><span class="tree-item-title">FMOpsLLMOps Operationalize Generative AI and Differences With MLOps</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/four-ways-that-enterprises-deploy-llms.html"><span class="tree-item-title">Four Ways That Enterprises Deploy LLMs</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/from-concept-to-practice-learnings-from-llms-for-enterprise-production-–-part-0.html"><span class="tree-item-title">From Concept to Practice Learnings From LLMs for Enterprise Production – Part 0</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/from-out-of-the-box-to-tailor-made-developing-and-deploying-enterprise-generative-ai-tools.html"><span class="tree-item-title">From Out-of-the-Box to Tailor-Made Developing and Deploying Enterprise Generative AI Tools</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/generative-ai-a-creative-new-world.html"><span class="tree-item-title">Generative AI A Creative New World</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/generative-ai-is-exploding-these-are-the-most-important-trends-to-know.html"><span class="tree-item-title">Generative AI Is Exploding. These Are the Most Important Trends to Know</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/generative-ai’s-act-two.html"><span class="tree-item-title">Generative AI’s Act Two</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/guardrails-for-llms-a-practical-approach-shreya-rajpal-llms-in-prod-conference-part-2.html"><span class="tree-item-title">Guardrails for LLMs A Practical Approach Shreya Rajpal LLMs in Prod Conference Part 2</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/guardrails-what-are-they-and-how-can-you-use-nemo-and-guardrails-ai-to-safeguard-llms.html"><span class="tree-item-title">Guardrails What Are They and How Can You Use NeMo and Guardrails AI to Safeguard LLMs</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/guiding-llms-while-staying-in-the-driver's-seat-jacob-van-gogh-llms-in-prod-con-lightning-talk.html"><span class="tree-item-title">Guiding LLMs While Staying in the Driver's Seat Jacob Van Gogh LLMs in Prod Con Lightning Talk</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/harry-browne’s-17-golden-rules-of-financial-safety.html"><span class="tree-item-title">Harry Browne’s 17 Golden Rules of Financial Safety</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/how-ray-solves-common-production-challenges-for-generative-ai-infrastructure.html"><span class="tree-item-title">How Ray Solves Common Production Challenges for Generative AI Infrastructure</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/how-to-evaluate-your-llm-applications.html"><span class="tree-item-title">How to Evaluate Your LLM Applications</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/illustrating-reinforcement-learning-from-human-feedback.html"><span class="tree-item-title">Illustrating Reinforcement Learning From Human Feedback</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/improving-llms-in-production-with-observability.html"><span class="tree-item-title">Improving LLMs in Production With Observability</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/introduction-to-retrieval-augmented-generation.html"><span class="tree-item-title">Introduction to Retrieval Augmented Generation</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/llm-deployment-with-nlp-models-meryem-arik-llms-in-production-conference-lightning-talk-2.html"><span class="tree-item-title">LLM Deployment With NLP Models Meryem Arik LLMs in Production Conference Lightning Talk 2</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/llm-evaluation-assessing-large-language-models-using-their-peers.html"><span class="tree-item-title">LLM Evaluation Assessing Large Language Models Using Their Peers</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/llm-observability-one-small-step-for-spans,-one-giant-leap-for-span-kinds.html"><span class="tree-item-title">LLM Observability One Small Step for Spans, One Giant Leap for Span-Kinds</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/llmops-the-future-of-mlops-for-generative-ai.html"><span class="tree-item-title">LLMOps The Future of MLOps for Generative AI</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/ml's-hidden-tasks-a-checklist-for-developers-when-building-ml-systems.html"><span class="tree-item-title">ML's Hidden Tasks A Checklist for Developers When Building ML Systems</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/monitoring-llms-metrics,-challenges,-&amp;-hallucinations.html"><span class="tree-item-title">Monitoring LLMs Metrics, Challenges, &amp; Hallucinations</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/no-rose-without-a-thorn-obstacles-to-successful-llm-deployments-tanmay-chopra-llms-in-prod.html"><span class="tree-item-title">No Rose Without a Thorn - Obstacles to Successful LLM Deployments Tanmay Chopra LLMs in Prod</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/nvidia-enables-trustworthy,-safe,-and-secure-large-language-model-conversational-systems.html"><span class="tree-item-title">NVIDIA Enables Trustworthy, Safe, and Secure Large Language Model Conversational Systems</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/production-deployment-checklist-for-machine-learning-models.html"><span class="tree-item-title">Production Deployment Checklist for Machine Learning Models</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/security-challenges-in-llm-adoption-for-enterprises-and-how-to-solve-them.html"><span class="tree-item-title">Security Challenges in LLM Adoption for Enterprises and How to Solve Them</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/the-confidence-checklist-for-llms-in-production-rohit-agarwal-llms-in-prod-conference-part-2.html"><span class="tree-item-title">The Confidence Checklist for LLMs in Production Rohit Agarwal LLMs in Prod Conference Part 2</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/the-generative-ai-life-cycle.html"><span class="tree-item-title">The Generative AI Life-Cycle</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/the-gradient-of-generative-ai-release-methods-and-considerations.html"><span class="tree-item-title">The Gradient of Generative AI Release Methods and Considerations</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/the-new-language-model-stack.html"><span class="tree-item-title">The New Language Model Stack</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/the_practical_guide_deploying_large_language_models.html"><span class="tree-item-title">The_Practical_Guide_Deploying_Large_Language_Models</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/understanding-llmops-large-language-model-operations.html"><span class="tree-item-title">Understanding LLMOps Large Language Model Operations</span></a></div><div class="tree-item-children"></div></div></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/glr-–-references.html"><span class="tree-item-title">GLR – References</span></a></div><div class="tree-item-children"></div></div></div></div><div class="tree-item mod-tree-file" data-depth="1"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="mind-map-–-generative-ai-release-checklist-3.html"><span class="tree-item-title">Mind Map – Generative AI Release Checklist 3</span></a></div><div class="tree-item-children"></div></div></div></div></div></div></div></div><div class="sidebar-gutter"><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div></div><div class="document-container show"><div class="markdown-preview-view markdown-rendered node-insert-event is-readable-line-width allow-fold-headings show-indentation-guide allow-fold-lists show-properties" style="tab-size:4"><style id="MJX-CHTML-styles">mjx-container[jax=CHTML]{line-height:0}mjx-container [space="1"]{margin-left:.111em}mjx-container [space="2"]{margin-left:.167em}mjx-container [space="3"]{margin-left:.222em}mjx-container [space="4"]{margin-left:.278em}mjx-container [space="5"]{margin-left:.333em}mjx-container [rspace="1"]{margin-right:.111em}mjx-container [rspace="2"]{margin-right:.167em}mjx-container [rspace="3"]{margin-right:.222em}mjx-container [rspace="4"]{margin-right:.278em}mjx-container [rspace="5"]{margin-right:.333em}mjx-container [size="s"]{font-size:70.7%}mjx-container [size=ss]{font-size:50%}mjx-container [size=Tn]{font-size:60%}mjx-container [size=sm]{font-size:85%}mjx-container [size=lg]{font-size:120%}mjx-container [size=Lg]{font-size:144%}mjx-container [size=LG]{font-size:173%}mjx-container [size=hg]{font-size:207%}mjx-container [size=HG]{font-size:249%}mjx-container [width=full]{width:100%}mjx-box{display:inline-block}mjx-block{display:block}mjx-itable{display:inline-table}mjx-row{display:table-row}mjx-row>*{display:table-cell}mjx-mtext{display:inline-block}mjx-mstyle{display:inline-block}mjx-merror{display:inline-block;color:red;background-color:#ff0}mjx-mphantom{visibility:hidden}mjx-assistive-mml{top:0;left:0;clip:rect(1px,1px,1px,1px);user-select:none;position:absolute!important;padding:1px 0 0!important;border:0!important;display:block!important;width:auto!important;overflow:hidden!important}mjx-assistive-mml[display=block]{width:100%!important}mjx-math{display:inline-block;text-align:left;line-height:0;text-indent:0;font-style:normal;font-weight:400;font-size:100%;letter-spacing:normal;border-collapse:collapse;overflow-wrap:normal;word-spacing:normal;white-space:nowrap;direction:ltr;padding:1px 0}mjx-container[jax=CHTML][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=CHTML][display=true][width=full]{display:flex}mjx-container[jax=CHTML][display=true] mjx-math{padding:0}mjx-container[jax=CHTML][justify=left]{text-align:left}mjx-container[jax=CHTML][justify=right]{text-align:right}mjx-mo{display:inline-block;text-align:left}mjx-stretchy-h{display:inline-table;width:100%}mjx-stretchy-h>*{display:table-cell;width:0}mjx-stretchy-h>*>mjx-c{display:inline-block;transform:scaleX(1)}mjx-stretchy-h>*>mjx-c::before{display:inline-block;width:initial}mjx-stretchy-h>mjx-ext{overflow:clip visible;width:100%}mjx-stretchy-h>mjx-ext>mjx-c::before{transform:scaleX(500)}mjx-stretchy-h>mjx-ext>mjx-c{width:0}mjx-stretchy-h>mjx-beg>mjx-c{margin-right:-.1em}mjx-stretchy-h>mjx-end>mjx-c{margin-left:-.1em}mjx-stretchy-v{display:inline-block}mjx-stretchy-v>*{display:block}mjx-stretchy-v>mjx-beg{height:0}mjx-stretchy-v>mjx-end>mjx-c{display:block}mjx-stretchy-v>*>mjx-c{transform:scaleY(1);transform-origin:left center;overflow:hidden}mjx-stretchy-v>mjx-ext{display:block;height:100%;box-sizing:border-box;border:0 solid transparent;overflow:visible clip}mjx-stretchy-v>mjx-ext>mjx-c::before{width:initial;box-sizing:border-box}mjx-stretchy-v>mjx-ext>mjx-c{transform:scaleY(500) translateY(.075em);overflow:visible}mjx-mark{display:inline-block;height:0}mjx-c{display:inline-block}mjx-utext{display:inline-block;padding:.75em 0 .2em}mjx-mi{display:inline-block;text-align:left}mjx-msup{display:inline-block;text-align:left}mjx-mn{display:inline-block;text-align:left}mjx-c::before{display:block;width:0}.MJX-TEX{font-family:MJXZERO,MJXTEX}.TEX-B{font-family:MJXZERO,MJXTEX-B}.TEX-I{font-family:MJXZERO,MJXTEX-I}.TEX-MI{font-family:MJXZERO,MJXTEX-MI}.TEX-BI{font-family:MJXZERO,MJXTEX-BI}.TEX-S1{font-family:MJXZERO,MJXTEX-S1}.TEX-S2{font-family:MJXZERO,MJXTEX-S2}.TEX-S3{font-family:MJXZERO,MJXTEX-S3}.TEX-S4{font-family:MJXZERO,MJXTEX-S4}.TEX-A{font-family:MJXZERO,MJXTEX-A}.TEX-C{font-family:MJXZERO,MJXTEX-C}.TEX-CB{font-family:MJXZERO,MJXTEX-CB}.TEX-FR{font-family:MJXZERO,MJXTEX-FR}.TEX-FRB{font-family:MJXZERO,MJXTEX-FRB}.TEX-SS{font-family:MJXZERO,MJXTEX-SS}.TEX-SSB{font-family:MJXZERO,MJXTEX-SSB}.TEX-SSI{font-family:MJXZERO,MJXTEX-SSI}.TEX-SC{font-family:MJXZERO,MJXTEX-SC}.TEX-T{font-family:MJXZERO,MJXTEX-T}.TEX-V{font-family:MJXZERO,MJXTEX-V}.TEX-VB{font-family:MJXZERO,MJXTEX-VB}mjx-stretchy-h mjx-c,mjx-stretchy-v mjx-c{font-family:MJXZERO,MJXTEX-S1,MJXTEX-S4,MJXTEX,MJXTEX-A!important}@font-face{font-family:MJXZERO;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Zero.woff") format("woff")}@font-face{font-family:MJXTEX;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Main-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-B;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Main-Bold.woff") format("woff")}@font-face{font-family:MJXTEX-I;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Math-Italic.woff") format("woff")}@font-face{font-family:MJXTEX-MI;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Main-Italic.woff") format("woff")}@font-face{font-family:MJXTEX-BI;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Math-BoldItalic.woff") format("woff")}@font-face{font-family:MJXTEX-S1;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Size1-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-S2;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Size2-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-S3;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Size3-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-S4;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Size4-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-A;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_AMS-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-C;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-CB;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Bold.woff") format("woff")}@font-face{font-family:MJXTEX-FR;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Fraktur-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-FRB;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Fraktur-Bold.woff") format("woff")}@font-face{font-family:MJXTEX-SS;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_SansSerif-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-SSB;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_SansSerif-Bold.woff") format("woff")}@font-face{font-family:MJXTEX-SSI;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_SansSerif-Italic.woff") format("woff")}@font-face{font-family:MJXTEX-SC;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Script-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-T;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Typewriter-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-V;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Vector-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-VB;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Vector-Bold.woff") format("woff")}mjx-c.mjx-c28::before{padding:.75em .389em .25em 0;content:"("}mjx-c.mjx-c1D43C.TEX-I::before{padding:.683em .504em 0 0;content:"I"}mjx-c.mjx-c1D434.TEX-I::before{padding:.716em .75em 0 0;content:"A"}mjx-c.mjx-c29::before{padding:.75em .389em .25em 0;content:")"}mjx-c.mjx-c33::before{padding:.665em .5em .022em 0;content:"3"}</style><div class="markdown-preview-sizer markdown-preview-section" style="min-height:1306px"><div class="markdown-preview-pusher" style="width:1px;height:.1px;margin-bottom:0"></div><div class="mod-header"></div><div><pre class="frontmatter language-yaml" tabindex="0" style="display:none"><code class="language-yaml is-loaded"><span class="token key atrule">tags</span><span class="token punctuation">:</span> project/grey<span class="token punctuation">-</span>llm type/blog type/literature type/note 
<span class="token key atrule">created</span><span class="token punctuation">:</span> <span class="token datetime number">2023-10-28</span>
<span class="token key atrule">link</span><span class="token punctuation">:</span> https<span class="token punctuation">:</span>//openai.com/blog/best<span class="token punctuation">-</span>practices<span class="token punctuation">-</span>for<span class="token punctuation">-</span>deploying<span class="token punctuation">-</span>language<span class="token punctuation">-</span>models</code><button class="copy-code-button">Copy</button></pre></div><div class="heading-wrapper"><h1 data-heading="Best Practices for Deploying Language Models" class="heading" id="Best_Practices_for_Deploying_Language_Models"><div class="heading-before"></div>Best Practices for Deploying Language Models<div class="heading-after">...</div></h1><div class="heading-children"><div><p><img alt="rw-book-cover" src="https://openai.com/content/images/2022/06/deploying-language-models-color.png" referrerpolicy="no-referrer"></p></div><div class="heading-wrapper"><h2 data-heading="Highlights" class="heading" id="Highlights"><div class="heading-before"></div><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle" style="width:24px;max-width:100%"><path d="M3 8L12 17L21 8"></path></svg></div>Highlights<div class="heading-after">...</div></h2><div class="heading-children"><div><ul><li data-line="0">Cohere, OpenAI, and AI21 Labs have developed a preliminary set of best practices applicable to any organization developing or deploying large language models. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hbxra6f8qn8b1skzdp6k0crp" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hbxra6f8qn8b1skzdp6k0crp" target="_blank">View Highlight</a>)</li><li data-line="1">While these principles were developed specifically based on our experience with providing LLMs through an API, we hope they will be useful regardless of release strategy (such as open-sourcing or use within a company). (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hbxs18gzh3zjsy2e2w7970d5" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hbxs18gzh3zjsy2e2w7970d5" target="_blank">View Highlight</a>)</li><li data-line="2"><strong>Publish usage guidelines and terms of use</strong> of LLMs in a way that prohibits material harm to individuals, communities, and society such as through spam, fraud, or astroturfing. Usage guidelines should also specify domains where LLM use requires extra scrutiny and prohibit high-risk use-cases that aren’t appropriate, such as classifying people based on protected characteristics. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hbxs2qb3rtvkt7yr32t6q51b" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hbxs2qb3rtvkt7yr32t6q51b" target="_blank">View Highlight</a>)</li><li data-line="3"><strong>Build systems and infrastructure to enforce usage guidelines</strong>. This may include rate limits, content filtering, application approval prior to production access, monitoring for anomalous activity, and other mitigations. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hbxs32v37szj5117gmfxm47w" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hbxs32v37szj5117gmfxm47w" target="_blank">View Highlight</a>)</li><li data-line="4">Mitigate unintentional harm (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hbxs35j5q4m0pdj1rtesvm8q" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hbxs35j5q4m0pdj1rtesvm8q" target="_blank">View Highlight</a>)</li><li data-line="5"><strong>Proactively mitigate harmful model behavior</strong>. Best practices include comprehensive model evaluation to properly assess limitations, minimizing potential sources of bias in training corpora, and techniques to minimize unsafe behavior such as through learning from human feedback. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hbxs3qt1ht027gn3yz7429gs" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hbxs3qt1ht027gn3yz7429gs" target="_blank">View Highlight</a>)</li><li data-line="6"><strong>Document known weaknesses and vulnerabilities</strong>, such as bias or ability to produce insecure code, as in some cases no degree of preventative action can completely eliminate the potential for unintended harm. Documentation should also include model and use-case-specific safety best practices. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hbxs4crzvc2gk0bh28h7s4cy" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hbxs4crzvc2gk0bh28h7s4cy" target="_blank">View Highlight</a>)</li><li data-line="7">Thoughtfully collaborate with stakeholders (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hbxsd3480s12fg7qayx5vxxn" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hbxsd3480s12fg7qayx5vxxn" target="_blank">View Highlight</a>)</li><li data-line="8"><strong>Build teams with diverse backgrounds</strong> and solicit broad input. Diverse perspectives are needed to characterize and address how language models will operate in the diversity of the real world, where if unchecked they may reinforce biases or fail to work for some groups. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hbxscs8nbmf34mk6k2rn467s" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hbxscs8nbmf34mk6k2rn467s" target="_blank">View Highlight</a>)</li><li data-line="9"><strong>Publicly disclose lessons learned regarding LLM safety and misuse</strong> in order to enable widespread adoption and help with cross-industry iteration on best practices. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hbxsczag6vbye22zxrgmkyjr" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hbxsczag6vbye22zxrgmkyjr" target="_blank">View Highlight</a>)</li><li data-line="10"><strong>Treat all labor in the language model supply chain with respect</strong>. For example, providers should have high standards for the working conditions of those reviewing model outputs in-house and hold vendors to well-specified standards (e.g., ensuring labelers are able to opt out of a given task). (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hbxsdp1kxawgkyqwnaxr7eaf" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hbxsdp1kxawgkyqwnaxr7eaf" target="_blank">View Highlight</a>)</li></ul></div><div class="mod-footer"></div></div></div></div></div></div></div></div><div class="sidebar-right sidebar"><div class="sidebar-gutter"><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-container"><div class="sidebar-sizer"><div class="sidebar-content-positioner"><div class="sidebar-content"><div class="graph-view-wrapper"><div class="sidebar-section-header">Interactive Graph</div><div class="graph-view-placeholder"><div class="graph-view-container"><div class="graph-icon graph-expand" role="button" aria-label="Expand" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><line x1="7" y1="17" x2="17" y2="7"></line><polyline points="7 7 17 7 17 17"></polyline></svg></div><canvas id="graph-canvas" width="512px" height="512px"></canvas></div></div></div><div class="tree-container outline-tree" data-depth="0"><div class="tree-header"><span class="sidebar-section-header">Table Of Contents</span><button class="clickable-icon collapse-tree-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></svg></button></div><div class="tree-scroll-area"><div class="tree-item" data-depth="1"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="#Best_Practices_for_Deploying_Language_Models"><span class="tree-item-title"><p>Best Practices for Deploying Language Models</p></span></a></div><div class="tree-item-children"><div class="tree-item" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="#Highlights"><span class="tree-item-title"><p>Highlights</p></span></a></div><div class="tree-item-children"></div></div></div></div></div></div></div></div></div></div></div></div></body></html>