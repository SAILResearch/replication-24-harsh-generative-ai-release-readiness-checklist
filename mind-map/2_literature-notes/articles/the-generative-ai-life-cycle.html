<!doctype html><html><head><title>The Generative AI Life-Cycle</title><base href="../../"><meta id="root-path" root-path="../../"><link rel="icon" sizes="96x96" href="https://publish-01.obsidian.md/access/f786db9fac45774fa4f0d8112e232d67/favicon-96x96.png"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=yes,minimum-scale=1,maximum-scale=5"><meta charset="UTF-8"><link rel="stylesheet" href="lib/styles/obsidian-styles.css"><link rel="stylesheet" href="lib/styles/theme.css"><link rel="stylesheet" href="lib/styles/plugin-styles.css"><link rel="stylesheet" href="lib/styles/snippets.css"><link rel="stylesheet" href="lib/styles/generated-styles.css"><style>body.css-settings-manager{--heading-spacing:0}</style><script type="module" src="lib/scripts/graph_view.js"></script><script src="lib/scripts/graph_wasm.js"></script><script src="lib/scripts/tinycolor.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/pixi.js/7.2.4/pixi.min.js" integrity="sha512-Ch/O6kL8BqUwAfCF7Ie5SX1Hin+BJgYH4pNjRqXdTEqMsis1TUYg+j6nnI9uduPjGaj7DN4UKCZgpvoExt6dkw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><script src="lib/scripts/webpage.js"></script><script src="lib/scripts/generated.js"></script></head><body class="theme-dark mod-macos native-scrollbars show-inline-title minimal-dracula-dark colorful-active system-shade minimal-dark-black callouts-default trim-cols checkbox-circle pdf-seamless-on pdf-invert-dark pdf-blend-light metadata-heading-off sidebar-tabs-default ribbon-hidden maximize-tables-off tabs-default tab-stack-top minimal-tab-title-hover is-fullscreen loading"><div class="webpage-container"><div class="sidebar-left sidebar"><div class="sidebar-container"><div class="sidebar-sizer"><div class="sidebar-content-positioner"><div class="sidebar-content"><div><label class="theme-toggle-container" for="theme_toggle"><input class="theme-toggle-input" type="checkbox" id="theme_toggle"><div class="toggle-background"></div></label></div><div class="tree-container file-tree mod-nav-indicator" data-depth="0"><div class="tree-header"><span class="sidebar-section-header">obsidian-notes</span><button class="clickable-icon collapse-tree-button is-collapsed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></svg></button></div><div class="tree-scroll-area"><div class="tree-item mod-tree-folder mod-collapsible is-collapsed" data-depth="1"><div class="tree-item-contents"><a class="internal-link tree-item-link"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">2_Literature Notes</span></a></div><div class="tree-item-children" style="display:none"><div class="tree-item mod-tree-folder mod-collapsible is-collapsed" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="tree-item-title">Articles</span></a></div><div class="tree-item-children" style="display:none"><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/3-things-chatgpt-needs-before-it-can-be-deployed-in-customer-service.html"><span class="tree-item-title">3 Things ChatGPT Needs Before it Can be Deployed in Customer Service</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/a-developer’s-guide-to-llmops-operationalizing-llms-at-scale.html"><span class="tree-item-title">A Developer’s Guide To LLMOps Operationalizing LLMs At Scale</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/age-of-industrialized-ai-dan-jeffries-llms-in-production-conference.html"><span class="tree-item-title">Age of Industrialized AI Dan Jeffries LLMs in Production Conference</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/ai-agents-when-and-how-to-implement.html"><span class="tree-item-title">AI Agents When and How to Implement</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/best-practices-for-deploying-language-models.html"><span class="tree-item-title">Best Practices for Deploying Language Models</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/best-practices-for-deploying-large-language-models-(llms)-in-production.html"><span class="tree-item-title">Best Practices for Deploying Large Language Models (LLMs) in Production</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/best-practices-for-large-language-model-(llm)-deployment.html"><span class="tree-item-title">Best Practices for Large Language Model (LLM) Deployment</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/best-practices-for-monitoring-large-language-models.html"><span class="tree-item-title">Best Practices for Monitoring Large Language Models</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/building-llm-applications-for-production-chip-huyen-llms-in-prod-conference.html"><span class="tree-item-title">Building LLM Applications for Production Chip Huyen LLMs in Prod Conference</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/comply-or-die-the-rise-of-the-ai-governance-stack.html"><span class="tree-item-title">Comply or Die The Rise of the AI Governance Stack</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/concepts-for-reliability-of-llms-in-production.html"><span class="tree-item-title">Concepts for Reliability of LLMs in Production</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/controlled-and-compliant-ai-applications-daniel-whitenack-llms-in-production-conference-part-2.html"><span class="tree-item-title">Controlled and Compliant AI Applications Daniel Whitenack LLMs in Production Conference Part 2</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/deploying-large-language-models-in-production-llm-deployment-challenges.html"><span class="tree-item-title">Deploying Large Language Models in Production LLM Deployment Challenges</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/deploying-large-language-models-in-production-orchestrating-llms.html"><span class="tree-item-title">Deploying Large Language Models in Production Orchestrating LLMs</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/deploying-large-language-models-in-production-the-anatomy-of-llm-applications.html"><span class="tree-item-title">Deploying Large Language Models in Production The Anatomy of LLM Applications</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/design-patterns-for-llm-systems-&amp;-products.html"><span class="tree-item-title">Design Patterns for LLM Systems &amp; Products</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/devtools-for-language-models-—-predicting-the-future.html"><span class="tree-item-title">DevTools for Language Models — Predicting the Future</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/edition-21-a-framework-to-securely-use-llms-in-companies-part-1-overview-of-risks.html"><span class="tree-item-title">Edition 21 A Framework to Securely Use LLMs in Companies - Part 1 Overview of Risks</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/edition-22-a-framework-to-securely-use-llms-in-companies-part-2-managing-risk.html"><span class="tree-item-title">Edition 22 A Framework to Securely Use LLMs in Companies - Part 2 Managing Risk</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/emerging-architectures-for-llm-applications.html"><span class="tree-item-title">Emerging Architectures for LLM Applications</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/emerging-architectures-for-llms-applications-datasciencedojo.html"><span class="tree-item-title">Emerging Architectures for LLMs Applications - datasciencedojo</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/emerging-patterns-for-llms-in-production-willem-pienaar-llms-in-prod-conference-lightning-talk.html"><span class="tree-item-title">Emerging Patterns for LLMs in Production Willem Pienaar LLMs in Prod Conference Lightning Talk</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/ensuring-accuracy-and-quality-in-llm-driven-products-adam-nolte-llms-in-prod-conference.html"><span class="tree-item-title">Ensuring Accuracy and Quality in LLM-driven Products Adam Nolte LLMs in Prod Conference</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/evaluating-rag-pipelines-with-ragas-+-langsmith.html"><span class="tree-item-title">Evaluating RAG Pipelines With Ragas + LangSmith</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/exploring-llm-apps-the-langchain-paradigm-and-future-alternatives.html"><span class="tree-item-title">Exploring LLM Apps The LangChain Paradigm and Future Alternatives</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/finetuning-large-language-models.html"><span class="tree-item-title">Finetuning Large Language Models</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/fmopsllmops-operationalize-generative-ai-and-differences-with-mlops.html"><span class="tree-item-title">FMOpsLLMOps Operationalize Generative AI and Differences With MLOps</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/four-ways-that-enterprises-deploy-llms.html"><span class="tree-item-title">Four Ways That Enterprises Deploy LLMs</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/from-concept-to-practice-learnings-from-llms-for-enterprise-production-–-part-0.html"><span class="tree-item-title">From Concept to Practice Learnings From LLMs for Enterprise Production – Part 0</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/from-out-of-the-box-to-tailor-made-developing-and-deploying-enterprise-generative-ai-tools.html"><span class="tree-item-title">From Out-of-the-Box to Tailor-Made Developing and Deploying Enterprise Generative AI Tools</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/generative-ai-a-creative-new-world.html"><span class="tree-item-title">Generative AI A Creative New World</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/generative-ai-is-exploding-these-are-the-most-important-trends-to-know.html"><span class="tree-item-title">Generative AI Is Exploding. These Are the Most Important Trends to Know</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/generative-ai’s-act-two.html"><span class="tree-item-title">Generative AI’s Act Two</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/guardrails-for-llms-a-practical-approach-shreya-rajpal-llms-in-prod-conference-part-2.html"><span class="tree-item-title">Guardrails for LLMs A Practical Approach Shreya Rajpal LLMs in Prod Conference Part 2</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/guardrails-what-are-they-and-how-can-you-use-nemo-and-guardrails-ai-to-safeguard-llms.html"><span class="tree-item-title">Guardrails What Are They and How Can You Use NeMo and Guardrails AI to Safeguard LLMs</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/guiding-llms-while-staying-in-the-driver's-seat-jacob-van-gogh-llms-in-prod-con-lightning-talk.html"><span class="tree-item-title">Guiding LLMs While Staying in the Driver's Seat Jacob Van Gogh LLMs in Prod Con Lightning Talk</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/harry-browne’s-17-golden-rules-of-financial-safety.html"><span class="tree-item-title">Harry Browne’s 17 Golden Rules of Financial Safety</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/how-ray-solves-common-production-challenges-for-generative-ai-infrastructure.html"><span class="tree-item-title">How Ray Solves Common Production Challenges for Generative AI Infrastructure</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/how-to-evaluate-your-llm-applications.html"><span class="tree-item-title">How to Evaluate Your LLM Applications</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/illustrating-reinforcement-learning-from-human-feedback.html"><span class="tree-item-title">Illustrating Reinforcement Learning From Human Feedback</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/improving-llms-in-production-with-observability.html"><span class="tree-item-title">Improving LLMs in Production With Observability</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/introduction-to-retrieval-augmented-generation.html"><span class="tree-item-title">Introduction to Retrieval Augmented Generation</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/llm-deployment-with-nlp-models-meryem-arik-llms-in-production-conference-lightning-talk-2.html"><span class="tree-item-title">LLM Deployment With NLP Models Meryem Arik LLMs in Production Conference Lightning Talk 2</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/llm-evaluation-assessing-large-language-models-using-their-peers.html"><span class="tree-item-title">LLM Evaluation Assessing Large Language Models Using Their Peers</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/llm-observability-one-small-step-for-spans,-one-giant-leap-for-span-kinds.html"><span class="tree-item-title">LLM Observability One Small Step for Spans, One Giant Leap for Span-Kinds</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/llmops-the-future-of-mlops-for-generative-ai.html"><span class="tree-item-title">LLMOps The Future of MLOps for Generative AI</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/ml's-hidden-tasks-a-checklist-for-developers-when-building-ml-systems.html"><span class="tree-item-title">ML's Hidden Tasks A Checklist for Developers When Building ML Systems</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/monitoring-llms-metrics,-challenges,-&amp;-hallucinations.html"><span class="tree-item-title">Monitoring LLMs Metrics, Challenges, &amp; Hallucinations</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/no-rose-without-a-thorn-obstacles-to-successful-llm-deployments-tanmay-chopra-llms-in-prod.html"><span class="tree-item-title">No Rose Without a Thorn - Obstacles to Successful LLM Deployments Tanmay Chopra LLMs in Prod</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/nvidia-enables-trustworthy,-safe,-and-secure-large-language-model-conversational-systems.html"><span class="tree-item-title">NVIDIA Enables Trustworthy, Safe, and Secure Large Language Model Conversational Systems</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/production-deployment-checklist-for-machine-learning-models.html"><span class="tree-item-title">Production Deployment Checklist for Machine Learning Models</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/security-challenges-in-llm-adoption-for-enterprises-and-how-to-solve-them.html"><span class="tree-item-title">Security Challenges in LLM Adoption for Enterprises and How to Solve Them</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/the-confidence-checklist-for-llms-in-production-rohit-agarwal-llms-in-prod-conference-part-2.html"><span class="tree-item-title">The Confidence Checklist for LLMs in Production Rohit Agarwal LLMs in Prod Conference Part 2</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/the-generative-ai-life-cycle.html"><span class="tree-item-title">The Generative AI Life-Cycle</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/the-gradient-of-generative-ai-release-methods-and-considerations.html"><span class="tree-item-title">The Gradient of Generative AI Release Methods and Considerations</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/the-new-language-model-stack.html"><span class="tree-item-title">The New Language Model Stack</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/the_practical_guide_deploying_large_language_models.html"><span class="tree-item-title">The_Practical_Guide_Deploying_Large_Language_Models</span></a></div><div class="tree-item-children"></div></div><div class="tree-item mod-tree-file" data-depth="3"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/articles/understanding-llmops-large-language-model-operations.html"><span class="tree-item-title">Understanding LLMOps Large Language Model Operations</span></a></div><div class="tree-item-children"></div></div></div></div><div class="tree-item mod-tree-file" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="2_literature-notes/glr-–-references.html"><span class="tree-item-title">GLR – References</span></a></div><div class="tree-item-children"></div></div></div></div><div class="tree-item mod-tree-file" data-depth="1"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="mind-map-–-generative-ai-release-checklist-3.html"><span class="tree-item-title">Mind Map – Generative AI Release Checklist 3</span></a></div><div class="tree-item-children"></div></div></div></div></div></div></div></div><div class="sidebar-gutter"><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div></div><div class="document-container show"><div class="markdown-preview-view markdown-rendered node-insert-event is-readable-line-width allow-fold-headings show-indentation-guide allow-fold-lists show-properties" style="tab-size:4"><style id="MJX-CHTML-styles">mjx-container[jax=CHTML]{line-height:0}mjx-container [space="1"]{margin-left:.111em}mjx-container [space="2"]{margin-left:.167em}mjx-container [space="3"]{margin-left:.222em}mjx-container [space="4"]{margin-left:.278em}mjx-container [space="5"]{margin-left:.333em}mjx-container [rspace="1"]{margin-right:.111em}mjx-container [rspace="2"]{margin-right:.167em}mjx-container [rspace="3"]{margin-right:.222em}mjx-container [rspace="4"]{margin-right:.278em}mjx-container [rspace="5"]{margin-right:.333em}mjx-container [size="s"]{font-size:70.7%}mjx-container [size=ss]{font-size:50%}mjx-container [size=Tn]{font-size:60%}mjx-container [size=sm]{font-size:85%}mjx-container [size=lg]{font-size:120%}mjx-container [size=Lg]{font-size:144%}mjx-container [size=LG]{font-size:173%}mjx-container [size=hg]{font-size:207%}mjx-container [size=HG]{font-size:249%}mjx-container [width=full]{width:100%}mjx-box{display:inline-block}mjx-block{display:block}mjx-itable{display:inline-table}mjx-row{display:table-row}mjx-row>*{display:table-cell}mjx-mtext{display:inline-block}mjx-mstyle{display:inline-block}mjx-merror{display:inline-block;color:red;background-color:#ff0}mjx-mphantom{visibility:hidden}mjx-assistive-mml{top:0;left:0;clip:rect(1px,1px,1px,1px);user-select:none;position:absolute!important;padding:1px 0 0!important;border:0!important;display:block!important;width:auto!important;overflow:hidden!important}mjx-assistive-mml[display=block]{width:100%!important}mjx-math{display:inline-block;text-align:left;line-height:0;text-indent:0;font-style:normal;font-weight:400;font-size:100%;letter-spacing:normal;border-collapse:collapse;overflow-wrap:normal;word-spacing:normal;white-space:nowrap;direction:ltr;padding:1px 0}mjx-container[jax=CHTML][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=CHTML][display=true][width=full]{display:flex}mjx-container[jax=CHTML][display=true] mjx-math{padding:0}mjx-container[jax=CHTML][justify=left]{text-align:left}mjx-container[jax=CHTML][justify=right]{text-align:right}mjx-mo{display:inline-block;text-align:left}mjx-stretchy-h{display:inline-table;width:100%}mjx-stretchy-h>*{display:table-cell;width:0}mjx-stretchy-h>*>mjx-c{display:inline-block;transform:scaleX(1)}mjx-stretchy-h>*>mjx-c::before{display:inline-block;width:initial}mjx-stretchy-h>mjx-ext{overflow:clip visible;width:100%}mjx-stretchy-h>mjx-ext>mjx-c::before{transform:scaleX(500)}mjx-stretchy-h>mjx-ext>mjx-c{width:0}mjx-stretchy-h>mjx-beg>mjx-c{margin-right:-.1em}mjx-stretchy-h>mjx-end>mjx-c{margin-left:-.1em}mjx-stretchy-v{display:inline-block}mjx-stretchy-v>*{display:block}mjx-stretchy-v>mjx-beg{height:0}mjx-stretchy-v>mjx-end>mjx-c{display:block}mjx-stretchy-v>*>mjx-c{transform:scaleY(1);transform-origin:left center;overflow:hidden}mjx-stretchy-v>mjx-ext{display:block;height:100%;box-sizing:border-box;border:0 solid transparent;overflow:visible clip}mjx-stretchy-v>mjx-ext>mjx-c::before{width:initial;box-sizing:border-box}mjx-stretchy-v>mjx-ext>mjx-c{transform:scaleY(500) translateY(.075em);overflow:visible}mjx-mark{display:inline-block;height:0}mjx-c{display:inline-block}mjx-utext{display:inline-block;padding:.75em 0 .2em}mjx-mi{display:inline-block;text-align:left}mjx-msup{display:inline-block;text-align:left}mjx-mn{display:inline-block;text-align:left}mjx-c::before{display:block;width:0}.MJX-TEX{font-family:MJXZERO,MJXTEX}.TEX-B{font-family:MJXZERO,MJXTEX-B}.TEX-I{font-family:MJXZERO,MJXTEX-I}.TEX-MI{font-family:MJXZERO,MJXTEX-MI}.TEX-BI{font-family:MJXZERO,MJXTEX-BI}.TEX-S1{font-family:MJXZERO,MJXTEX-S1}.TEX-S2{font-family:MJXZERO,MJXTEX-S2}.TEX-S3{font-family:MJXZERO,MJXTEX-S3}.TEX-S4{font-family:MJXZERO,MJXTEX-S4}.TEX-A{font-family:MJXZERO,MJXTEX-A}.TEX-C{font-family:MJXZERO,MJXTEX-C}.TEX-CB{font-family:MJXZERO,MJXTEX-CB}.TEX-FR{font-family:MJXZERO,MJXTEX-FR}.TEX-FRB{font-family:MJXZERO,MJXTEX-FRB}.TEX-SS{font-family:MJXZERO,MJXTEX-SS}.TEX-SSB{font-family:MJXZERO,MJXTEX-SSB}.TEX-SSI{font-family:MJXZERO,MJXTEX-SSI}.TEX-SC{font-family:MJXZERO,MJXTEX-SC}.TEX-T{font-family:MJXZERO,MJXTEX-T}.TEX-V{font-family:MJXZERO,MJXTEX-V}.TEX-VB{font-family:MJXZERO,MJXTEX-VB}mjx-stretchy-h mjx-c,mjx-stretchy-v mjx-c{font-family:MJXZERO,MJXTEX-S1,MJXTEX-S4,MJXTEX,MJXTEX-A!important}@font-face{font-family:MJXZERO;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Zero.woff") format("woff")}@font-face{font-family:MJXTEX;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Main-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-B;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Main-Bold.woff") format("woff")}@font-face{font-family:MJXTEX-I;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Math-Italic.woff") format("woff")}@font-face{font-family:MJXTEX-MI;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Main-Italic.woff") format("woff")}@font-face{font-family:MJXTEX-BI;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Math-BoldItalic.woff") format("woff")}@font-face{font-family:MJXTEX-S1;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Size1-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-S2;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Size2-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-S3;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Size3-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-S4;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Size4-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-A;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_AMS-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-C;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-CB;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Bold.woff") format("woff")}@font-face{font-family:MJXTEX-FR;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Fraktur-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-FRB;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Fraktur-Bold.woff") format("woff")}@font-face{font-family:MJXTEX-SS;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_SansSerif-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-SSB;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_SansSerif-Bold.woff") format("woff")}@font-face{font-family:MJXTEX-SSI;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_SansSerif-Italic.woff") format("woff")}@font-face{font-family:MJXTEX-SC;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Script-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-T;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Typewriter-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-V;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Vector-Regular.woff") format("woff")}@font-face{font-family:MJXTEX-VB;src:url("https://publish.obsidian.md/lib/mathjax/output/chtml/fonts/woff-v2/MathJax_Vector-Bold.woff") format("woff")}mjx-c.mjx-c28::before{padding:.75em .389em .25em 0;content:"("}mjx-c.mjx-c1D43C.TEX-I::before{padding:.683em .504em 0 0;content:"I"}mjx-c.mjx-c1D434.TEX-I::before{padding:.716em .75em 0 0;content:"A"}mjx-c.mjx-c29::before{padding:.75em .389em .25em 0;content:")"}mjx-c.mjx-c33::before{padding:.665em .5em .022em 0;content:"3"}</style><div class="markdown-preview-sizer markdown-preview-section" style="min-height:1306px"><div class="markdown-preview-pusher" style="width:1px;height:.1px;margin-bottom:0"></div><div class="mod-header"></div><div><pre class="frontmatter language-yaml" tabindex="0" style="display:none"><code class="language-yaml is-loaded"><span class="token key atrule">tags</span><span class="token punctuation">:</span> project/grey<span class="token punctuation">-</span>llm type/blog type/literature type/note 
<span class="token key atrule">created</span><span class="token punctuation">:</span> <span class="token datetime number">2023-10-28</span>
<span class="token key atrule">link</span><span class="token punctuation">:</span> https<span class="token punctuation">:</span>//dr<span class="token punctuation">-</span>arsanjani.medium.com/the<span class="token punctuation">-</span>generative<span class="token punctuation">-</span>ai<span class="token punctuation">-</span>life<span class="token punctuation">-</span>cycle<span class="token punctuation">-</span>fb2271a70349</code><button class="copy-code-button">Copy</button></pre></div><div class="heading-wrapper"><h1 data-heading="The Generative AI Life-Cycle" class="heading" id="The_Generative_AI_Life-Cycle"><div class="heading-before"></div>The Generative AI Life-Cycle<div class="heading-after">...</div></h1><div class="heading-children"><div><p><img alt="rw-book-cover" src="https://miro.medium.com/v2/resize:fit:960/1*cLMf30_ksinIr-q6VnoH_g.jpeg" referrerpolicy="no-referrer"></p></div><div class="heading-wrapper"><h2 data-heading="Highlights" class="heading" id="Highlights"><div class="heading-before"></div><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle" style="width:24px;max-width:100%"><path d="M3 8L12 17L21 8"></path></svg></div>Highlights<div class="heading-after">...</div></h2><div class="heading-children"><div><ul><li data-line="0">Let’s highlight the contrasting aspects between generative and predictive AI: (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hcjew9eavgmm22mg47fcdv69" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hcjew9eavgmm22mg47fcdv69" target="_blank">View Highlight</a>)</li><li data-line="1">Another approach is the Teacher-student few-shot approach to producing smaller models. This approach is actually a variant of knowledge distillation, but it specifically focuses on few-shot learning — the ability to learn from a small number of examples. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hcjf4286bff934wzgsehm2a3" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hcjf4286bff934wzgsehm2a3" target="_blank">View Highlight</a>)</li><li data-line="2">• <strong>Postprocess the Output</strong>. After the output is generated, it may require postprocessing to make it usable for downstream tasks. This may involve converting the output from numerical embeddings to text, resizing images, or applying other transformations. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hcjf5f8xdmmtfeasqka2v6kp" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hcjf5f8xdmmtfeasqka2v6kp" target="_blank">View Highlight</a>)</li><li data-line="3">Prompt-tuning, Prompt design: Optimize prompts used in language generation models to improve quality, coherence, and relevance. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hcjf5sqp4kmpcbjm5n801j42" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hcjf5sqp4kmpcbjm5n801j42" target="_blank">View Highlight</a>)</li><li data-line="4"><strong>Prompt design</strong>. In this phase, you design the initial prompt that will be used to generate responses from your language model. The prompt should be carefully crafted to elicit the desired type of response and to provide enough context for the model to generate coherent and relevant output. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hcjf6fqdp93f7t6en97whakn" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hcjf6fqdp93f7t6en97whakn" target="_blank">View Highlight</a>)</li><li data-line="5"><strong>Prompt tuning</strong>. Once you have a draft prompt, you’ll need to fine-tune it to improve the quality of the responses generated by your language model. This might involve tweaking the wording of the prompt, adjusting the level of detail provided, or adding additional context or constraints to guide the model’s output. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hcjf76dz3e428pwx76hwkf8m" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hcjf76dz3e428pwx76hwkf8m" target="_blank">View Highlight</a>)</li><li data-line="6"><strong>Instruction tuning</strong>. In addition to tuning the prompt itself, you may also need to provide additional instructions or guidance to the model to help it generate the type of output you’re looking for. This might involve specifying certain criteria for the output, providing sample outputs to use as references, or setting constraints on the content or style of the generated text. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hcjf7sxfnpgeczx2r3q5vh2n" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hcjf7sxfnpgeczx2r3q5vh2n" target="_blank">View Highlight</a>)</li><li data-line="7"><strong>Fine-tuning</strong>. Once you have a well-designed prompt and clear instructions for your model, you’ll need to fine-tune the model itself to optimize its performance on your specific task. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hcjf8qqj6f1w95htndj82w2n" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hcjf8qqj6f1w95htndj82w2n" target="_blank">View Highlight</a>)</li></ul></div></div></div><div class="heading-wrapper"><h2 data-heading="New highlights added 2023-10-30 at 7:12 PM" class="heading" id="New_highlights_added_2023-10-30_at_7:12_PM"><div class="heading-before"></div><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle" style="width:24px;max-width:100%"><path d="M3 8L12 17L21 8"></path></svg></div>New highlights added 2023-10-30 at 7:12 PM<div class="heading-after">...</div></h2><div class="heading-children"><div><ul><li data-line="0">Among the frenzy and noise, it remains important to continue to develop generative AI models that are fair, accurate, safe and secure. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw5yrf6d8hk8gd9t46vt0wp" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw5yrf6d8hk8gd9t46vt0wp" target="_blank">View Highlight</a>)</li><li data-line="1"><strong>Data Collection</strong>: Collect data from various sources including internet, social media, sensors, and optimally data warehouses like Google BigQuery or Google Cloud Storage. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw5yde1wx8h7kpxh28fp5qy" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw5yde1wx8h7kpxh28fp5qy" target="_blank">View Highlight</a>)</li><li data-line="2"><strong>Data Creation</strong>: Optionally generate/use synthetic data to augment existing datasets to achieve better performance metrics on trained models. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw5yytftwb3w7dp6jrk0gzh" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw5yytftwb3w7dp6jrk0gzh" target="_blank">View Highlight</a>)</li><li data-line="3"><strong>Data Curation</strong>: Clean and organize data through filtering, transformation, integration and labeling of data for supervised learning. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw5z18ffzfscrbj0wq7e8g5" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw5z18ffzfscrbj0wq7e8g5" target="_blank">View Highlight</a>)</li><li data-line="4"><strong>Feature Storage</strong>: Store the gold standard of features that have been painstakingly curated and prepped. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw5z4m8zgjek5cx9v6wpa3g" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw5z4m8zgjek5cx9v6wpa3g" target="_blank">View Highlight</a>)</li><li data-line="5"><strong>Data Bias Check</strong>. This is an essential step in the machine learning lifecycle, especially for generative AI models, to ensure that the training data and the generated content is fair, unbiased, and representative of the underlying data distribution. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw5z9v2c3mj33xzn9j6ccrg" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw5z9v2c3mj33xzn9j6ccrg" target="_blank">View Highlight</a>)</li><li data-line="6">Data Inspection: Examine the collected data to identify potential biases or imbalances. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw60w6fdrc7gdk4tt4j9prv" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw60w6fdrc7gdk4tt4j9prv" target="_blank">View Highlight</a>)</li><li data-line="7">Bias Mitigation Techniques: Apply various techniques to mitigate the identified biases in the data. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw61jdxpsypb4kqt2w59r1n" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw61jdxpsypb4kqt2w59r1n" target="_blank">View Highlight</a>)</li><li data-line="8">Model Evaluation: Develop evaluation metrics and techniques that specifically assess the model’s fairness and bias. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw61835p00g1ztt9pr6xqrg" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw61835p00g1ztt9pr6xqrg" target="_blank">View Highlight</a>)</li><li data-line="9">Continuous Monitoring: After deploying the generative AI model, monitor its performance and outputs to ensure that biases do not emerge over time. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw63vfqeqfn1rcj54q6h195" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw63vfqeqfn1rcj54q6h195" target="_blank">View Highlight</a>)</li><li data-line="10">Set up feedback loops to gather user feedback and input, which can be used to identify and address any newly discovered biases. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw6418bxj9qb9n2m29wbvsx" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw6418bxj9qb9n2m29wbvsx" target="_blank">View Highlight</a>)</li><li data-line="11">Transparency and Accountability: Document and share the steps taken to address data bias in the generative AI model. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw64vx364kx2gg5dbcd0sq6" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw64vx364kx2gg5dbcd0sq6" target="_blank">View Highlight</a>)</li><li data-line="12">Communicate the model’s limitations and potential biases to end-users and stakeholders, fostering trust and setting realistic expectations for the model’s performance. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw657dsxj1famdawq0sp455" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw657dsxj1famdawq0sp455" target="_blank">View Highlight</a>)</li><li data-line="13">Distillation<br>Train or create a much smaller model with similar performance and downstream task capabilities by using a student/teacher few-shot learning approach to train a much smaller model, or, prune a model to arrive at a smaller footprint deployable model. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw6aa5nn4kx03tddpbm32rr" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw6aa5nn4kx03tddpbm32rr" target="_blank">View Highlight</a>)</li><li data-line="15"><strong>Pruning</strong>: This involves removing unimportant weights or neurons from the LLM while preserving its accuracy. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw6aetsdm43gxffkwqzbg51" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw6aetsdm43gxffkwqzbg51" target="_blank">View Highlight</a>)</li><li data-line="16"><strong>Quantization</strong>: This involves reducing the precision of the LLM’s weights and activations. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw6ahvs8vmhtjrz0x8h3f70" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw6ahvs8vmhtjrz0x8h3f70" target="_blank">View Highlight</a>)</li><li data-line="17"><strong>Knowledge Distillation</strong>: This involves training a smaller model to mimic the output of the LLM on a set of training examples. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw6amy3mdrkvmh3dcrx60jf" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw6amy3mdrkvmh3dcrx60jf" target="_blank">View Highlight</a>)</li><li data-line="18"><strong>Low-rank Factorization</strong>: This involves decomposing the weight matrices of the LLM into low-rank matrices. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw6atksvbdp30zwrcbhnjmw" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw6atksvbdp30zwrcbhnjmw" target="_blank">View Highlight</a>)</li><li data-line="19"><strong>Compact Embeddings</strong>: This involves reducing the dimensionality of the input and output embeddings of the LLM. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw6b0f99yreenpkgy83wgy6" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw6b0f99yreenpkgy83wgy6" target="_blank">View Highlight</a>)</li><li data-line="20"><strong>Architectural Changes</strong>: This involves changing the architecture of the LLM to make it more efficient. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw6b76w911ykcy0zhfafexb" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw6b76w911ykcy0zhfafexb" target="_blank">View Highlight</a>)</li><li data-line="21"><strong>Parameter Sharing</strong>: This involves sharing parameters between different parts of the model. (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw6br6eg39y42f1pvw26d5c" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw6br6eg39y42f1pvw26d5c" target="_blank">View Highlight</a>)</li><li data-line="22">Data and model drift. Monitor and managing changes in data distribution and model performance over time (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw6jcb6mzrrmngxtqd5jcba" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw6jcb6mzrrmngxtqd5jcba" target="_blank">View Highlight</a>)</li><li data-line="23">Model versioning. Manage different versions of the model for traceability, reproducibility, and comparison (<a data-tooltip-position="top" aria-label="https://read.readwise.io/read/01hdw6jz6b41vwwt7s3pnefmkv" rel="noopener" class="external-link" href="https://read.readwise.io/read/01hdw6jz6b41vwwt7s3pnefmkv" target="_blank">View Highlight</a>)</li></ul></div><div class="mod-footer"></div></div></div></div></div></div></div></div><div class="sidebar-right sidebar"><div class="sidebar-gutter"><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-container"><div class="sidebar-sizer"><div class="sidebar-content-positioner"><div class="sidebar-content"><div class="graph-view-wrapper"><div class="sidebar-section-header">Interactive Graph</div><div class="graph-view-placeholder"><div class="graph-view-container"><div class="graph-icon graph-expand" role="button" aria-label="Expand" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><line x1="7" y1="17" x2="17" y2="7"></line><polyline points="7 7 17 7 17 17"></polyline></svg></div><canvas id="graph-canvas" width="512px" height="512px"></canvas></div></div></div><div class="tree-container outline-tree" data-depth="0"><div class="tree-header"><span class="sidebar-section-header">Table Of Contents</span><button class="clickable-icon collapse-tree-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></svg></button></div><div class="tree-scroll-area"><div class="tree-item" data-depth="1"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="#The_Generative_AI_Life-Cycle"><span class="tree-item-title"><p>The Generative AI Life-Cycle</p></span></a></div><div class="tree-item-children"><div class="tree-item" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="#Highlights"><span class="tree-item-title"><p>Highlights</p></span></a></div><div class="tree-item-children"></div></div><div class="tree-item" data-depth="2"><div class="tree-item-contents"><a class="internal-link tree-item-link" href="#New_highlights_added_2023-10-30_at_7:12_PM"><span class="tree-item-title"><p>New highlights added 2023-10-30 at 7:12 PM</p></span></a></div><div class="tree-item-children"></div></div></div></div></div></div></div></div></div></div></div></div></body></html>